{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSETUPSVCPORT: 23210\n",
      "ACSVCPORT: 17532\n",
      "ALLUSERSPROFILE: C:\\ProgramData\n",
      "ANACONDA_HOME: C:\\ProgramData\\anaconda3\n",
      "APPCODE_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\appcode.vmoptions\n",
      "APPDATA: C:\\Users\\Administrator\\AppData\\Roaming\n",
      "APPLICATIONINSIGHTS_CONFIGURATION_CONTENT: {}\n",
      "APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL: true\n",
      "BETTERNCM_PROFILE: C:\\Users\\Administrator\\BetterNCM\n",
      "CHOCOLATEYINSTALL: C:\\ProgramData\\chocolatey\n",
      "CHOCOLATEYLASTPATHUPDATE: 133426277199629245\n",
      "CHROME_CRASHPAD_PIPE_NAME: \\\\.\\pipe\\crashpad_69092_NFZXZGCTRQNIKKCH\n",
      "CLION_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\clion.vmoptions\n",
      "COMMONPROGRAMFILES: C:\\Program Files\\Common Files\n",
      "COMMONPROGRAMFILES(X86): C:\\Program Files (x86)\\Common Files\n",
      "COMMONPROGRAMW6432: C:\\Program Files\\Common Files\n",
      "COMPUTERNAME: AKIS4070\n",
      "COMSPEC: C:\\WINDOWS\\system32\\cmd.exe\n",
      "CONDA_DEFAULT_ENV: base\n",
      "CONDA_EXE: C:\\ProgramData\\anaconda3\\Scripts\\conda.exe\n",
      "CONDA_PREFIX: C:\\ProgramData\\anaconda3\n",
      "CONDA_PROMPT_MODIFIER: (base) \n",
      "CONDA_PYTHON_EXE: C:\\ProgramData\\anaconda3\\python.exe\n",
      "CONDA_ROOT: C:\\ProgramData\\anaconda3\n",
      "CONDA_SHLVL: 1\n",
      "CUDA_PATH: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\n",
      "CUDA_PATH_V12_2: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\n",
      "CUDA_PATH_V12_3: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\n",
      "DATAGRIP_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\datagrip.vmoptions\n",
      "DATASPELL_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\dataspell.vmoptions\n",
      "DEVECOSTUDIO_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\devecostudio.vmoptions\n",
      "DRIVERDATA: C:\\Windows\\System32\\Drivers\\DriverData\n",
      "EFC_219740: 1\n",
      "ELECTRON_RUN_AS_NODE: 1\n",
      "ENABLELOG: INFO\n",
      "FPS_BROWSER_APP_PROFILE_STRING: Internet Explorer\n",
      "FPS_BROWSER_USER_PROFILE_STRING: Default\n",
      "GATEWAY_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\gateway.vmoptions\n",
      "GOLAND_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\goland.vmoptions\n",
      "HOMEDRIVE: C:\n",
      "HOMEPATH: \\Users\\Administrator\n",
      "IDEA_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\idea.vmoptions\n",
      "INTELLIJ IDEA: C:\\Program Files\\JetBrains\\IntelliJ IDEA 2023.2.3\\bin;\n",
      "JAVA_HOME: C:\\Program Files\\Java\\jdk-21\n",
      "JETBRAINSCLIENT_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\jetbrainsclient.vmoptions\n",
      "JETBRAINS_CLIENT_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\jetbrains_client.vmoptions\n",
      "JPY_INTERRUPT_EVENT: 1604\n",
      "LOCALAPPDATA: C:\\Users\\Administrator\\AppData\\Local\n",
      "LOGONSERVER: \\\\AKIS4070\n",
      "MSMPI_BENCHMARKS: C:\\Program Files\\Microsoft MPI\\Benchmarks\\\n",
      "MSMPI_BIN: C:\\Program Files\\Microsoft MPI\\Bin\\\n",
      "NEST_MUSIC: C:\\Users\\Administrator\\Music\\App\n",
      "NUMBER_OF_PROCESSORS: 20\n",
      "NVM_HOME: C:\\Users\\Administrator\\AppData\\Roaming\\nvm\n",
      "NVM_SYMLINK: C:\\Program Files\\nodejs\n",
      "ONEDRIVE: C:\\Users\\Administrator\\OneDrive\n",
      "ONEDRIVECONSUMER: C:\\Users\\Administrator\\OneDrive\n",
      "OPENSSL_IA32CAP: ~0x200000200000000\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP: undefined\n",
      "OS: Windows_NT\n",
      "PATH: c:\\ProgramData\\anaconda3;C:\\ProgramData\\anaconda3;C:\\ProgramData\\anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\anaconda3\\Library\\usr\\bin;C:\\ProgramData\\anaconda3\\Library\\bin;C:\\ProgramData\\anaconda3\\Scripts;C:\\ProgramData\\anaconda3\\bin;C:\\ProgramData\\anaconda3\\condabin;C:\\Users\\Administrator\\Music\\App;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.3\\libnvvp;C:\\Program Files\\Microsoft MPI\\Bin;C:\\Python312\\Scripts;C:\\Python312;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\libnvvp;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn;C:\\Program Files\\dotnet;C:\\Program Files\\Microsoft VS Code\\bin;C:\\Program Files\\Java\\jdk-21\\bin;C:\\Program Files\\Java\\jdk-21\\lib;C:\\Program Files\\Git\\cmd;C:\\ProgramData\\anaconda3;C:\\ProgramData\\anaconda3\\Scripts;C:\\ProgramData\\anaconda3\\Library;ANACONDA_HOME\\ProgramData\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Administrator\\Tool\\platform-tools;C:\\ProgramData\\chocolatey\\bin;C:\\Windows\\system32\\config\\systemprofile\\AppData\\Roaming\\nvm;C:\\Program Files\\nodejs;C:\\Users\\Administrator\\AppData\\Local\\NVIDIA\\ChatWithRTX\\env_nvd_rag\\Lib\\site-packages\\torch\\lib;C:\\Program Files (x86)\\Windows Kits\\10\\Windows Performance Toolkit;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2023.3.0;C:\\Program Files\\MongoDB\\Server\\7.0\\bin;C:\\Users\\Administrator\\Documents\\BaiduSyncdisk\\MyCommand;C:\\Program Files\\Pandoc;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Users\\Administrator\\adb;.;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files\\CMake\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\WINDOWS\\System32\\OpenSSH;C:\\Users\\Administrator\\scoop\\shims;C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Administrator\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\Administrator\\AppData\\Roaming\\nvm;C:\\Program Files\\nodejs;C:\\Program Files\\JetBrains\\IntelliJ IDEA 2023.2.3\\bin;.;C:\\Users\\Administrator\\.dotnet\\tools;C:\\Users\\Administrator\\AppData\\Local\\Programs\\Ollama;C:\\Users\\Administrator\\Music\\App;.\n",
      "PATHEXT: .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW\n",
      "PHPSTORM_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\phpstorm.vmoptions\n",
      "PROCESSOR_ARCHITECTURE: AMD64\n",
      "PROCESSOR_IDENTIFIER: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "PROCESSOR_LEVEL: 6\n",
      "PROCESSOR_REVISION: b701\n",
      "PROGRAMDATA: C:\\ProgramData\n",
      "PROGRAMFILES: C:\\Program Files\n",
      "PROGRAMFILES(X86): C:\\Program Files (x86)\n",
      "PROGRAMW6432: C:\\Program Files\n",
      "PROMPT: (base) $P$G\n",
      "PSMODULEPATH: C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\n",
      "PUBLIC: C:\\Users\\Public\n",
      "PYCHARM_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\pycharm.vmoptions\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING: 1\n",
      "PYTHONIOENCODING: utf-8\n",
      "PYTHONUNBUFFERED: 1\n",
      "PYTHONUTF8: 1\n",
      "PYTHON_FROZEN_MODULES: on\n",
      "RIDER_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\rider.vmoptions\n",
      "RLSSVCPORT: 22112\n",
      "RUBYMINE_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\rubymine.vmoptions\n",
      "SESSIONNAME: Console\n",
      "STUDIO_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\studio.vmoptions\n",
      "SYSTEMDRIVE: C:\n",
      "SYSTEMROOT: C:\\WINDOWS\n",
      "TEMP: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\n",
      "TMP: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\n",
      "USERDOMAIN: AKIS4070\n",
      "USERDOMAIN_ROAMINGPROFILE: AKIS4070\n",
      "USERNAME: Administrator\n",
      "USERPROFILE: C:\\Users\\Administrator\n",
      "VSCODE_CODE_CACHE_PATH: C:\\Users\\Administrator\\AppData\\Roaming\\Code\\CachedData\\f1a4fb101478ce6ec82fe9627c43efbf9e98c813\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE: extensionHost\n",
      "VSCODE_CWD: C:\\Program Files\\Microsoft VS Code\n",
      "VSCODE_ESM_ENTRYPOINT: vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS: true\n",
      "VSCODE_IPC_HOOK: \\\\.\\pipe\\c5f8be1b-1.95.3-main-sock\n",
      "VSCODE_L10N_BUNDLE_LOCATION: \n",
      "VSCODE_NLS_CONFIG: {\"userLocale\":\"en-us\",\"osLocale\":\"zh-cn\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"C:\\\\Program Files\\\\Microsoft VS Code\\\\resources\\\\app\\\\out\\\\nls.messages.json\",\"locale\":\"en-us\",\"availableLanguages\":{}}\n",
      "VSCODE_PID: 69092\n",
      "WEBIDE_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\webide.vmoptions\n",
      "WEBSTORM_VM_OPTIONS: C:\\Program Files\\JetBrains\\jetbra\\vmoptions\\webstorm.vmoptions\n",
      "WINDIR: C:\\WINDOWS\n",
      "_CONDA_OLD_CHCP: 936\n",
      "PYDEVD_USE_FRAME_EVAL: NO\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "FORCE_COLOR: 1\n",
      "CLICOLOR_FORCE: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 读取所有环境变量\n",
    "env_vars = os.environ\n",
    "\n",
    "# 打印每个环境变量的名称和值\n",
    "for var, value in env_vars.items():\n",
    "    print(f'{var}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"function\", \"function\": {\"name\": \"close_light\", \"description\": \"\\u5173\\u6389\\u673a\\u7bb1\\u7684\\u706f\"}}]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "# 打开并读取YAML文件\n",
    "with open('ToolConfig.yml', 'r', encoding='utf-8') as file:\n",
    "    config_yml = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# 打印读取的数据\n",
    "print(json.dumps(config_yml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"qwen2:1.5b\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from tools import tool\n",
    "import ollama\n",
    "\n",
    "tools = []\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是Alice,是YakumoAki在设计的智能语音助手\"}\n",
    "    ]\n",
    "\n",
    "import yaml\n",
    "model_name = 'qwen2.5:1.5b'\n",
    "    # 打开并读取YAML文件\n",
    "with open('ToolConfig.yml', 'r', encoding='utf-8') as file:\n",
    "        tools = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "def chat(msg):\n",
    "    messages.append({'role': 'user', 'content': msg})\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    messages.append(response[\"message\"])\n",
    "    if tool_calls := messages[-1].get(\"tool_calls\", None):\n",
    "        for tool_call in tool_calls:\n",
    "            if fn_call := tool_call.get(\"function\"):\n",
    "                fn_name: str = fn_call[\"name\"]\n",
    "                fn_args: dict = fn_call[\"arguments\"]\n",
    "                fn_res: str = globals()(fn_name)(**fn_args)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": fn_name,\n",
    "                    \"content\": fn_res,\n",
    "                })\n",
    "    response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "    messages.append(response[\"message\"])\n",
    "    return messages[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 06:22:13.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1m[{'type': 'function', 'function': {'name': 'close_light', 'description': '关掉机箱的灯。', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}, {'type': 'function', 'function': {'name': 'open_light', 'description': '打开机箱的灯。', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "from tools import tool_config\n",
    "import ollama\n",
    "class OllamaQW():\n",
    "    # 加载tool文件中所有工具函数\n",
    "    import importlib\n",
    "    module_name = 'tools.tool_list'\n",
    "    module = importlib.import_module(module_name)\n",
    "    # 加载工具函数定义\n",
    "    tools = tool_config.tools\n",
    "    \n",
    "    # 模型预设\n",
    "    base_message = [\n",
    "            {\"role\": \"system\", \"content\": \"你是Alice,是YakumoAki在设计的智能语音助手\"}\n",
    "        ]\n",
    "    messages = []\n",
    "    def __init__(self, model_name: str):\n",
    "        import yaml\n",
    "        self.model_name = model_name\n",
    "        logger.info(self.tools)\n",
    "        \n",
    "    def chat(self, msg):\n",
    "        self.messages.append({'role': 'user', 'content': msg})\n",
    "        logger.info(f\"input message: {self.messages[-1]}\")\n",
    "        response = ollama.chat(\n",
    "            model=self.model_name,\n",
    "            messages=self.base_message + self.messages[-20:],\n",
    "            tools=self.tools,\n",
    "        )\n",
    "        self.messages.append(response[\"message\"])\n",
    "        logger.info(f\"model response is: {response}\")\n",
    "        if tool_calls := self.messages[-1].get(\"tool_calls\", None):\n",
    "            for tool_call in tool_calls:\n",
    "                if fn_call := tool_call.get(\"function\"):\n",
    "                    fn_name: str = fn_call[\"name\"]\n",
    "                    fn_args: dict = fn_call[\"arguments\"]\n",
    "                    logger.info(f\"function name: {fn_name}\")\n",
    "                    logger.info(f\"function args: {fn_args}\")\n",
    "                    my_function = getattr(self.module, fn_name)\n",
    "                    fn_res: str = my_function(**fn_args)\n",
    "\n",
    "                    self.messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": fn_name,\n",
    "                        \"content\": fn_res,\n",
    "                    })\n",
    "                    logger.info(f\"tool response is: {self.messages[-1]}\")\n",
    "            response = ollama.chat(\n",
    "                model=self.model_name,\n",
    "                messages=self.base_message + self.messages[-20:],\n",
    "                tools=self.tools,\n",
    "            )\n",
    "            self.messages.append(response[\"message\"])\n",
    "            logger.info(f\"model response is: {response}\")\n",
    "        return self.messages[-1]\n",
    "\n",
    "\n",
    "\n",
    "qw = OllamaQW(model_name='qwen2.5:3b')\n",
    "# qw.chat('关了机箱的灯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 06:19:27.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1minput message: {'role': 'user', 'content': '打开机箱的灯'}\u001b[0m\n",
      "\u001b[32m2025-01-13 06:19:27.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mmodel response is: model='qwen2.5:3b' created_at='2025-01-12T22:19:27.5021813Z' done=True done_reason='stop' total_duration=164421000 load_duration=10788900 prompt_eval_count=188 prompt_eval_duration=2000000 eval_count=16 eval_duration=148000000 message=Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='open_light', arguments={}))])\u001b[0m\n",
      "\u001b[32m2025-01-13 06:19:27.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mfunction name: open_light\u001b[0m\n",
      "\u001b[32m2025-01-13 06:19:27.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mfunction args: {}\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tools' has no attribute 'open_light'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mqw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m打开机箱的灯\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m, in \u001b[0;36mOllamaQW.chat\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m my_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m fn_res: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m my_function(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: fn_name,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: fn_res,\n\u001b[0;32m     46\u001b[0m })\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tools' has no attribute 'open_light'"
     ]
    }
   ],
   "source": [
    "qw.chat('打开机箱的灯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 06:17:48.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1minput message: {'role': 'user', 'content': 'close light'}\u001b[0m\n",
      "\u001b[32m2025-01-13 06:17:48.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mmodel response is: model='qwen2.5:3b' created_at='2025-01-12T22:17:48.5153795Z' done=True done_reason='stop' total_duration=162822400 load_duration=11395600 prompt_eval_count=244 prompt_eval_duration=6000000 eval_count=16 eval_duration=139000000 message=Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='close_light', arguments={}))])\u001b[0m\n",
      "\u001b[32m2025-01-13 06:17:48.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mfunction name: close_light\u001b[0m\n",
      "\u001b[32m2025-01-13 06:17:48.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mfunction args: {}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "执行cmd指令=\"\"C:\\Users\\Administrator\\Downloads\\OpenRGB_0.9_Windows_64_b5f46e3\\OpenRGB Windows 64-bit\\OpenRGB.exe\" --profile close\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 06:17:57.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mtool response is: {'role': 'tool', 'name': 'close_light', 'content': '关了'}\u001b[0m\n",
      "\u001b[32m2025-01-13 06:17:57.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mmodel response is: model='qwen2.5:3b' created_at='2025-01-12T22:17:57.8182852Z' done=True done_reason='stop' total_duration=145111500 load_duration=10451200 prompt_eval_count=280 prompt_eval_duration=3000000 eval_count=11 eval_duration=123000000 message=Message(role='assistant', content='好的，已经关掉了机箱的灯。', images=None, tool_calls=None)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content='好的，已经关掉了机箱的灯。', images=None, tool_calls=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw.chat('close light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 06:22:32.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1minput message: {'role': 'user', 'content': '你好啊'}\u001b[0m\n",
      "\u001b[32m2025-01-13 06:22:32.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mchat\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mmodel response is: model='qwen2.5:3b' created_at='2025-01-12T22:22:32.8661244Z' done=True done_reason='stop' total_duration=103655400 load_duration=11545500 prompt_eval_count=185 prompt_eval_duration=4000000 eval_count=8 eval_duration=86000000 message=Message(role='assistant', content='你好！有什么可以帮助你的吗？', images=None, tool_calls=None)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice: 你好！有什么可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    msg = input(\">: \")\n",
    "    if msg.lower() == 'exit':\n",
    "         break\n",
    "    res = qw.chat(msg)\n",
    "    print(f\"Alice: {res['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
